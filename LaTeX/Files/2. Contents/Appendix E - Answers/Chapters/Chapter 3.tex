\setcounter{chapter}{3}
\setcounter{section}{1}
\setcounter{answer}{0}

\section{Chapter 3: Confidence intervals and hypothesis testing}

\answer{
    \begin{minipage}[t]{.5\textwidth}
    $N = 4513$ \\
    $n = 100$ \\
    $\bar{x} = 145$ 
    \end{minipage}
    \begin{minipage}[t]{.5\textwidth}
    $s = 25$ \\
    $\sigma = $ unknown \\
    $\mu = $ unknown
    \end{minipage}
}

\answer{
    $\mu = $ 145 seconds \\
\\
\underline{Explanation}: The best estimate for the population mean $\mu$ is the sample mean $\bar{x}$.
}

\answer{
    $SE_\mu = \frac{s}{\sqrt{n}} = \frac{25}{\sqrt{100}} = 2.5$
}

\answer{
    z-value: 2.576 \\
\\
\underline{Explanation}: In table 2 of the formula sheet, the cumulative probability in that lies the closest to 0.995 (split the risk over two sides) is 0.9949. That value can be found at a z-value of 2.576. \\
\\
Lower bound: $\bar{x} - z_{0.995} \times SE_\mu = 145 - 2.567 \times 2.5 = 138.56$ \\
Upper bound: $\bar{x} + z_{0.995} \times SE_\mu = 145 - 2.567 \times 2.5 = 151.44$
}

\answer{
    $\mu_0 = 150$ (the to be tested limit of 150 seconds for the actual population mean call duration). \\
    \\
    $H_0: \mu \geq \mu_0$ \hspace*{4cm} $H_1: \mu < \mu_0$
}

\answer{
    Upper bound: $\bar{x} + z_{0.95} \times SE_\mu = 145 - 1.645 \times 2.5 = 149.11$
}

\answer{
    The upper bound of the confidence interval for $\mu$ is lower than $\mu_0$. $H_0$ is rejected with 95\% confidence. $\mu$ is shown to be significantly lower than 150 seconds. There is a risk of 5\% for a type-I error.
}

\answerbreakline \setcounter{section}{2} \setcounter{answer}{0}

\clearpage % Page break

\answer{
    \vspace*{1pt}
    \begin{tabular}{|c|c|r|r|}
    \hline 
    $i$ & $x_i$ & $(x_i - \bar{x})$ & $(x_i - \bar{x})^2$ \tstrut\bstrut\\
    \hline
    1 & 3.03 & -0.0863 & 0.0074 \tstrut\bstrut\\
    \hline
    2 & 3.45 & 0.3338 & 0.1114 \tstrut\bstrut\\
    \hline
    3 & 3.94 & 0.8238 & 0.6786 \tstrut\bstrut\\
    \hline
    4 & 2.34 & -0.7763 & 0.6026 \tstrut\bstrut\\
    \hline
    5 & 3.34 & 0.2238 & 0.0501 \tstrut\bstrut\\
    \hline
    6 & 2.53 & -0.5863 & 0.3437 \tstrut\bstrut\\
    \hline
    7 & 2.88 & -0.2363 & 0.0558 \tstrut\bstrut\\
    \hline
    8 & 3.42 & 0.3038 & 0.0923 \tstrut\bstrut\\
    \hline
    \end{tabular} \\
    \\
    $\sum x_i = 24.93$  \hspace*{.4cm} $\sum (x_i - \bar{x})^2 = 1.9418$ \\
    \\
    \hspace*{10pt} $\bar{x} = 3.116$ \hspace*{2cm} $s^2 = 0.277$ \\
}

\answer{
    Hartley's F: $\frac{s^2_min}{s^{max}} = \frac{1.113}{0.227} = 4.018$
}

\answer{
    $H_0: \sigma^2_1 = \sigma^2_2 = \sigma^2_3$ \hspace*{4cm} $H_0: \sigma^2_1 \neq \sigma^2_2 \neq \sigma^2_3$
}

\answer{
    Hartley's $F_{max}$: 6.94
}

\answer{
    The value $F = 4.018$ is lower than critical value $F_{max} = 6.94$. $H_0$ is not rejected. There is no indication the variance for these months is not homogeneous. There is a risk of a type-II error.
}

\answerbreakline \setcounter{section}{3} \setcounter{answer}{0}

\answer{
    \vspace*{-10pt}
    \answercode{{\color{dataset}\# Be sure to set your working directory when providing a relative path} \\
dataset5 <- read.csv(\textquotesingle populations.csv\textquotesingle)}
}

\answer{
    The code creates four random samples of size 90 from the columns \rcode{P1} - \rcode{P4} in the data frame called \rcode{dataset5}. The seed makes sure that you can recreate the same random samples again, so that if you close \texttt{R} and continue tomorrow we get the same samples. \\
    \\
    \answercode{set.seed(54321) {\color{dataset} \# You can replace 54321 with your own seed number} \\
\\
sample1 <- sample(dataset5\$P1, size = 90)\\
sample2 <- sample(dataset5\$P2, size = 90)\\
sample3 <- sample(dataset5\$P3, size = 90)\\
sample4 <- sample(dataset5\$P4, size = 90)}
}

\clearpage % Page break

\answer{
    Standard error sample 1: 29.24 \\
    Standard error sample 2: 7.64 \\
    Standard error sample 3: 30.61 \\
    Standard error sample 4: 18.09 \\
    \\
    \answercode{{\color{dataset}\# Means} \\
x1 <- mean(sample1) {\color{dataset} \# Mean: 456.78} \\
x2 <- mean(sample2) {\color{dataset} \# Mean: 511.02} \\
x3 <- mean(sample3) {\color{dataset} \# Mean: 790.32} \\
x4 <- mean(sample4) {\color{dataset} \# Mean: 533.37} \\
\\
{\color{dataset} \# Standard deviations} \\
sd1 <- sd(sample1) {\color{dataset} \# Standard deviation: 277.38} \\
sd2 <- sd(sample2) {\color{dataset} \# Standard deviation: 72.43} \\
sd3 <- sd(sample3) {\color{dataset} \# Standard deviation: 290.46} \\
sd4 <- sd(sample4) {\color{dataset} \# Standard deviation: 171.58} \\
\\
{\color{dataset} \# Standard errors se = sd / sqrt(n)} \\
se1 <- sd1 / sqrt(length(sample1))    {\color{dataset} \# Standard error: 29.24} \\
se2 <- sd2 / sqrt(length(sample2))    {\color{dataset} \# Standard error: 7.64} \\
se3 <- sd3 / sqrt(length(sample3))    {\color{dataset} \# Standard error: 30.61} \\
se4 <- sd4 / sqrt(length(sample4))    {\color{dataset} \# Standard error: 18.09}
    }
}

\answer{
    The value 1.644854 comes from the standard normal distribution with $\mu = 0$ and $\sigma = 1$. This is the z-value for a 95\% one-sided confidence interval (or a 90\% two-sided confidence interval).
}

\answer{
    \vspace*{-10pt}
    \answercode{{\color{dataset} \# Gives the left-tailed probability (z-value) for 95\% confidence} \\
qnorm(p = 0.95) {\color{dataset} \# 1.645}}
}

\answer{
    In a 95\% confidence interval there is 2.5\% of the risk at the lower bound and 2.5\% of the risk at the upper bound. You can therefore use the 97.5\% quantile of the standard normal distribution to get the z-value for a two-sided 95\% confidence interval and use it for both upper and lower bound. \\
    \\
    \answercode{z <- qnorm(p = 0.975)}
}

\clearpage % Page break

\answer{
    \vspace*{-10pt}
    \answercode{{\color{dataset} \# Lower bounds} \\
lb1 <- x1 - z * se1 {\color{dataset}\# Lower bound: 399.48} \\
lb2 <- x2 - z * se2 {\color{dataset}\# Lower bound: 496.06} \\
lb3 <- x3 - z * se3 {\color{dataset}\# Lower bound: 730.31} \\
lb4 <- x4 - z * se4 {\color{dataset}\# Lower bound: 497.92} \\
 \\
{\color{dataset}\# Upper bounds} \\
ub1 <- x1 + z * se1 {\color{dataset}\# Upper bound: 514.10} \\
ub2 <- x2 + z * se2 {\color{dataset}\# Upper bound: 525.99} \\
ub3 <- x3 + z * se3 {\color{dataset}\# Upper bound: 850.33} \\
ub4 <- x4 + z * se4 {\color{dataset}\# Upper bound: 568.81}}
}

\answer{
    \vspace*{1pt}
    \begin{center}
    \begin{tabular}{r|c|c|c|c|}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{\rcode{sample1}} & \multicolumn{1}{c}{\rcode{sample2}} & \multicolumn{1}{c}{\rcode{sample3}} & \multicolumn{1}{c}{\rcode{sample4}} \tstrut\bstrut\\
    \cline{2-5}
    \rcode{ub} & 514.10 & 525.99 & 850.33 & 568.81 \tstrut\bstrut\\
    \cline{2-5}
    \rcode{x} & 456.78 & 511.01 & 790.32 & 533.37 \tstrut\bstrut\\
    \cline{2-5}
    \rcode{lb} & 399.48 & 496.06 & 730.31 & 497.92 \tstrut\bstrut\\
    \cline{2-5}
    \end{tabular}
    \end{center}
    
    \begin{center}
    \begin{tabular}{r|c|c|c|c|}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{\rcode{P1}} & \multicolumn{1}{c}{\rcode{P2}} & \multicolumn{1}{c}{\rcode{P3}} & \multicolumn{1}{c}{\rcode{P4}} \tstrut\bstrut\\
    \cline{2-5}
    \rcode{mu} & 495.54 & 500.08 & 748.96 & 556.43 \tstrut\bstrut\\
    \cline{2-5}
    \textit{mu in interval?} & YES & YES & YES & YES \tstrut\bstrut\\
    \cline{2-5}
    \end{tabular}
    \end{center}
    \\
    \answercode{{\color{dataset}\# Population means} \\
mu1 <- mean(dataset5\$P1) {\color{dataset}\# Mean: 495.54} \\
mu2 <- mean(dataset5\$P2) {\color{dataset}\# Mean: 500.08} \\
mu3 <- mean(dataset5\$P3) {\color{dataset}\# Mean: 748.96} \\
mu4 <- mean(dataset5\$P4) {\color{dataset}\# Mean: 556.43}}
}

\answer{
    Yes, in this case all population means are inside the intervals.
}

\answer{
    The population mean will fall inside the interval 95 out of a 100 times (95\% confidence). This means that about 1 in 20 confidence intervals will not have the true population mean between their lower and upper bound.
}

\answerbreakline \setcounter{section}{4} \setcounter{answer}{0}

\clearpage % Page break

\answer{
    \vspace*{-10pt}
    \answercode{{\color{dataset}\# install.packages(\textquotesingle car\textquotesingle)} \\
library(car)  \\
 \\
{\color{dataset}\# This create a 2x2 layout} \\
layout(matrix(c(1, 2, 3, 4), byrow = TRUE, nrow = 2)) \\
 \\
hist(sample1, col = \textquotesingle gray\textquotesingle) \\
hist(sample2, col = \textquotesingle gray\textquotesingle) \\
hist(sample3, col = \textquotesingle gray\textquotesingle) \\
hist(sample4, col = \textquotesingle gray\textquotesingle) \\
 \\
{\color{dataset}\# This resets the layout to the default (1 plot)} \\
layout(1)
}
}

\answer{
    Sample 2 looks like it might come from a normal distribution.
}

\answer{
    \vspace*{-10pt}
    \answercode{{\color{dataset}\# This create a 2x2 layout} \\
layout(matrix(c(1, 2, 3, 4), byrow = TRUE, nrow = 2)) \\
 \\
qqPlot(sample1, distribution = \textquotesingle norm\textquotesingle) \\
qqPlot(sample2, distribution = \textquotesingle norm\textquotesingle) \\
qqPlot(sample3, distribution = \textquotesingle norm\textquotesingle) \\
qqPlot(sample4, distribution = \textquotesingle norm\textquotesingle) \\
 \\
{\color{dataset}\# This resets the layout to the default (1 plot)} \\
layout(1)
}
}

\clearpage % Page break

\answer{
    The \rcode{sample1} histogram looks normal in the middle, but has too many low and too many high values. This can be seen in the qqplot by the dots on the left of the diagonal at the bottom and the dots on the right at the top. \\
\\
The \rcode{sample2} histogram looks normal so the dots in the qqplot are almost everywhere on the diagonal. Only in the right part of the middle the histogram frequency is a bit too low, this is reflected in the dots below the diagonal around zero in the qqplot.\\

The \rcode{sample3} histogram is too high on the sides (or too low in the middle) to be normal. This can be seen in the qqplot by the dots on the left of the diagonal at the bottom and the dots on the right at the top.\\
\\
\rcode{sample4} is negatively skewed. This can be seen in the qqplot from the arch shape; the left of the histogram is too low causing the dots on the right of the diagonal and the right of the histogram is too high also causing dots to the right of the diagonal.
}

\answer{
    $H_0$: The sample is normally distributed\\
    $H_1$: The sample is not normally distributed
}

\answer{
    Samples 1, 3, and 4 are not normally distributed, since the p-value is lower than 1\% (for 99\% confidence). Sample 2 is normally distributed, since the p-value is higher than 1\%. \\
    \\
    \answercode{shapiro.test(sample1) {\color{dataset}\# p-value: 0.0022} \\
shapiro.test(sample2) {\color{dataset}\# p-value: 0.949} \\
shapiro.test(sample3) {\color{dataset}\# p-value: 0.0068} \\
shapiro.test(sample4) {\color{dataset}\# p-value: 0.0001}}
}

\answer{
    When the sample is not normally distributed, the sample can be used to estimate the population mean. \\
 \\
\underline{Explanation}: This method to estimate the population mean assumes the distribution of sample means to be normally distributed. It does not assume a normally distributed sample. The Central Limit Theorem states that any sample large enough ($n \geq 30$) will have a normal distribution of sample means, so you can use this method here ($n = 90$) without problems.
}

\answerbreakline \setcounter{section}{5} \setcounter{answer}{0}

\clearpage

\answer{  
    \vspace*{-10pt}
    \answercode{library(car) \\
data(iris) \\
 \\
plot(x = iris\$Species, y = iris\$Sepal.Length, \\
     \hspace*{20pt}col = \textquotesingle grey\textquotesingle, main = \textquotesingle Sepal Length\textquotesingle) \\
 \\
plot(x = iris\$Species, y = iris\$Sepal.Width, \\
     \hspace*{20pt}col = \textquotesingle grey\textquotesingle, main = \textquotesingle Sepal Width\textquotesingle)
}
}

\answer{
    Looking at the width of the range and quartile ranges: For sepal length the variance for setosa looks much smaller than for the other two species, for sepal width all variances look similar.
}

\answer{
    $H_0: \sigma^2_1 = \sigma^2_2 = \sigma^2_3$ \hspace*{4cm} $H_0: \sigma^2_1 \neq \sigma^2_2 \neq \sigma^2_3$
}

\answer{
    The p-value for the sepal length is lower than 10\%. This implies that $H_0$ is rejected. This means that the variance of the sepal length over the species is not homogeneous. There is a 5\% change of a type-I error. \\
\\
The p-value for the sepal with is not lower than 10\%. This implies that $H_0$ is not rejected. This means that there is no indication that the variance of the sepal width over the species is not homogeneous. There is a risk of a type-II error. \\
\\
\answercode{{\color{dataset}\# Levene's Test for Homogeneity of Variance} \\
leveneTest(y = iris\$Sepal.Length,  \\
           group = iris\$Species) {\color{dataset}\# p-value: 0.002259} \\
 \\
leveneTest(y = iris\$Sepal.Width,  \\
           group = iris\$Species) {\color{dataset}\# p-value: 0.5555}}
}

\clearpage % Page break